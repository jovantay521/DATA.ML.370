{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Starting Letter Count\")\\\n",
    "    .master(\"local[4]\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.textFile('sample.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This code processes the input text by performing several transformations on the RDD.\n",
    "It splits the text into words, cleans the words, and then extracts the first letter\n",
    "of each word, ultimately preparing the data for counting word occurrences by starting letter.\n",
    "'''\n",
    "mapped_rdd = rdd.flatMap(lambda line: line.split())\\\n",
    "    .map(lambda word: re.sub(r'[^a-zA-Z\\s]', '', word).lower().strip())\\\n",
    "    .filter(lambda word: word and not word.isdigit())\\\n",
    "    .map(lambda word: (word[0].lower(), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('t', 1), ('p', 1), ('g', 1), ('e', 1), ('o', 1)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_rdd = mapped_rdd.reduceByKey(lambda a, b: a + b)\\\n",
    "    .sortBy(lambda x: x[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('t', 11585), ('a', 7983), ('s', 6048), ('h', 5877), ('w', 5479)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter: t, Count: 11585\n",
      "Letter: a, Count: 7983\n",
      "Letter: s, Count: 6048\n",
      "Letter: h, Count: 5877\n",
      "Letter: w, Count: 5479\n",
      "Letter: i, Count: 4303\n",
      "Letter: o, Count: 4184\n",
      "Letter: c, Count: 4178\n",
      "Letter: b, Count: 3915\n",
      "Letter: m, Count: 3689\n",
      "Letter: f, Count: 2754\n",
      "Letter: l, Count: 2525\n",
      "Letter: d, Count: 2426\n",
      "Letter: p, Count: 2323\n",
      "Letter: g, Count: 1815\n",
      "Letter: n, Count: 1707\n",
      "Letter: r, Count: 1341\n",
      "Letter: y, Count: 1318\n",
      "Letter: e, Count: 1217\n",
      "Letter: u, Count: 807\n",
      "Letter: k, Count: 489\n",
      "Letter: j, Count: 418\n",
      "Letter: v, Count: 392\n",
      "Letter: q, Count: 183\n",
      "Letter: x, Count: 42\n",
      "Letter: z, Count: 1\n"
     ]
    }
   ],
   "source": [
    "result = reduced_rdd.collect()\n",
    "for letter, count in result:\n",
    "    print(f\"Letter: {letter}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
